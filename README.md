# Finetune_Resume_Question-Answers

This repository contains the fine-tuned LLaMA 3.1 3B Instruct model for resume screening, using a Kaggle dataset. It includes the fine-tuning process and an inference notebook to test the model.

Contents
  
    ğŸ“Œ Completed_Resume_FineTune_kaggleData_03_14_25.ipynb â€“ Jupyter Notebook for fine-tuning the model
    
    ğŸ“Œ Test_Inference.ipynb â€“ Jupyter Notebook for testing the fine-tuned model

Technologies & Libraries Used

      ğŸ§  Model: LLaMA 3.1 3B Instruct (Meta AI)
      ğŸ“Š Dataset: Kaggle Resume Dataset
      ğŸ”¥ Fine-Tuning: LoRA (Low-Rank Adaptation)
      ğŸ–¥ Framework: PyTorch
      âš¡ Training Accelerator: Google Cloud T4 GPU
      ğŸ”¢ Libraries:
                
                Transformers (Hugging Face)

                PEFT (Parameter-Efficient Fine-Tuning)
                
                Bitsandbytes (8-bit and 4-bit quantization)
                
                PyTorch Lightning (for efficient training)
                
                Tokenizers (for text processing)
                

Model Storage

      âœ… Fine-tuned model saved on Hugging Face for easy access and deployment

Features
      
      âœ… Fine-tuned LLaMA 3.1 8B model for resume screening
      âœ… Optimized with LoRA for parameter-efficient training
      âœ… Uses quantization for reduced memory footprint
      âœ… Includes an inference notebook for easy testing
      âœ… Provides perfect answers when asked questions from

Usage

          1ï¸âƒ£ Fine-tune the model using Completed_Resume_FineTune_kaggleData_03_14_25.ipynb
          
          2ï¸âƒ£ Test inference with Test_Inference.ipynb on new resume data
          
          3ï¸âƒ£ Modify and improve based on your specific resume data



ğŸš€ Coming Soon: API deployment & real-world integration!
